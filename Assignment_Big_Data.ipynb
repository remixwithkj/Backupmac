{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPnbEj2DGTG9GWWzwaQAb2e",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/remixwithkj/Backupmac/blob/main/Assignment_Big_Data.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 687
        },
        "id": "iGU8cfP1WHjw",
        "outputId": "d56aa3a1-550f-40f2-bcdc-af33f237544c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r0% [Working]\r            \rGet:1 http://security.ubuntu.com/ubuntu jammy-security InRelease [129 kB]\n",
            "Get:2 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  InRelease [1,581 B]\n",
            "Hit:3 http://archive.ubuntu.com/ubuntu jammy InRelease\n",
            "Ign:4 https://r2u.stat.illinois.edu/ubuntu jammy InRelease\n",
            "Get:5 http://archive.ubuntu.com/ubuntu jammy-updates InRelease [128 kB]\n",
            "Get:6 https://r2u.stat.illinois.edu/ubuntu jammy Release [5,713 B]\n",
            "Get:7 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  Packages [1,031 kB]\n",
            "Get:8 https://r2u.stat.illinois.edu/ubuntu jammy Release.gpg [793 B]\n",
            "Get:9 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ InRelease [3,626 B]\n",
            "Get:10 http://archive.ubuntu.com/ubuntu jammy-backports InRelease [127 kB]\n",
            "Hit:11 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy InRelease\n",
            "Get:12 http://security.ubuntu.com/ubuntu jammy-security/universe amd64 Packages [1,161 kB]\n",
            "Hit:13 https://ppa.launchpadcontent.net/graphics-drivers/ppa/ubuntu jammy InRelease\n",
            "Get:14 https://r2u.stat.illinois.edu/ubuntu jammy/main amd64 Packages [2,596 kB]\n",
            "Hit:15 https://ppa.launchpadcontent.net/ubuntugis/ppa/ubuntu jammy InRelease\n",
            "Get:16 http://security.ubuntu.com/ubuntu jammy-security/main amd64 Packages [2,326 kB]\n",
            "Get:17 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 Packages [2,645 kB]\n",
            "Get:18 https://r2u.stat.illinois.edu/ubuntu jammy/main all Packages [8,391 kB]\n",
            "Get:19 http://archive.ubuntu.com/ubuntu jammy-updates/restricted amd64 Packages [3,272 kB]\n",
            "Get:20 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 Packages [1,450 kB]\n",
            "Get:21 http://archive.ubuntu.com/ubuntu jammy-backports/universe amd64 Packages [33.7 kB]\n",
            "Fetched 23.3 MB in 3s (8,461 kB/s)\n",
            "Reading package lists... Done\n",
            "W: Skipping acquire of configured file 'main/source/Sources' as repository 'https://r2u.stat.illinois.edu/ubuntu jammy InRelease' does not seem to provide it (sources.list entry misspelt?)\n",
            "sample_data  spark-3.1.1-bin-hadoop3.2\tspark-3.1.1-bin-hadoop3.2.tgz\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<pyspark.sql.session.SparkSession at 0x799544171870>"
            ],
            "text/html": [
              "\n",
              "            <div>\n",
              "                <p><b>SparkSession - in-memory</b></p>\n",
              "                \n",
              "        <div>\n",
              "            <p><b>SparkContext</b></p>\n",
              "\n",
              "            <p><a href=\"http://1eeff8e943a8:4040\">Spark UI</a></p>\n",
              "\n",
              "            <dl>\n",
              "              <dt>Version</dt>\n",
              "                <dd><code>v3.1.1</code></dd>\n",
              "              <dt>Master</dt>\n",
              "                <dd><code>local[*]</code></dd>\n",
              "              <dt>AppName</dt>\n",
              "                <dd><code>pyspark-shell</code></dd>\n",
              "            </dl>\n",
              "        </div>\n",
              "        \n",
              "            </div>\n",
              "        "
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "source": [
        "!apt-get update # Update apt-get repository.\n",
        "!apt-get install openjdk-8-jdk-headless -qq > /dev/null # Install Java.\n",
        "!wget -q http://archive.apache.org/dist/spark/spark-3.1.1/spark-3.1.1-bin-hadoop3.2.tgz # Download Apache Sparks.\n",
        "!tar xf spark-3.1.1-bin-hadoop3.2.tgz # Unzip the tgz file.\n",
        "!pip install -q findspark # Install findspark. Adds PySpark to the System path during runtime.\n",
        "\n",
        "# Set environment variables\n",
        "import os\n",
        "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n",
        "os.environ[\"SPARK_HOME\"] = \"/content/spark-3.1.1-bin-hadoop3.2\"\n",
        "\n",
        "!ls\n",
        "\n",
        "# Initialize findspark\n",
        "import findspark\n",
        "findspark.init()\n",
        "\n",
        "# Create a PySpark session\n",
        "from pyspark.sql import SparkSession\n",
        "spark = SparkSession.builder.master(\"local[*]\").getOrCreate()\n",
        "spark"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import sys # To acess system specific information about undelying interpreter and OS.\n",
        "from pyspark import SparkConf, SparkContext # Importing classes SparkConf, and SparkContext to work with Spark in Python.\n",
        "from math import sqrt # Importing sqrt function from math module in core Python"
      ],
      "metadata": {
        "id": "W_CHebO4Wsks"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def loadMovieNames(): # Defines a function named loadMovieNames\n",
        "    movieNames = {} # Initialising an empty dictionary named movieNames\n",
        "    with open(\"/home/cloudera/moviedata/itemfile.txt\") as f: #reads the file at the path defined and store it in file object f\n",
        "        for line in f: #loop to iterate through each line\n",
        "            fields = line.split('|') #splits lines into fields wherever encounters pipe i.e. |\n",
        "            movieNames[int(fields[0])] = fields[1].decode('ascii', 'ignore') #appends movie id as key and movie name as value in the movieNames dictionary initialised earlier\n",
        "    return movieNames # returns the dictionary with key-value pair of movie id and name respectively\n"
      ],
      "metadata": {
        "id": "arUR7WnzYqSD"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def makePairs( (user, ratings) ): # Defining fuction makePairs to accept a tuple argument where user is a user_id while ratings is a list of tuples each tuple has movie Id and rating by the user\n",
        "  (movie1, rating1) = ratings[0] # unpacks first item (0 index) in rating and assigns values to movie1 and rating1 respectively\n",
        "  (movie2, rating2) = ratings[1] # unpacks second item (1st index) in rating and assigns values to movie1 and rating1 respectively\n",
        "  return ((movie1, movie2), (rating1, rating2)) # returns a nested tuple, with movie pair and their correpinding ratings"
      ],
      "metadata": {
        "id": "psprMlZKaiUr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def filterDuplicates( (userID, ratings) ): # Defining fuction filterDuplicates to accept a tuple argument where user is a user_id while ratings is a list of tuples each tuple has movie Id and rating by the user\n",
        "    (movie1, rating1) = ratings[0] # unpacks first item (0 index) in rating and assigns values to movie1 and rating1 respectively\n",
        "    (movie2, rating2) = ratings[1] # unpacks second item (1st index) in rating and assigns values to movie1 and rating1 respectively\n",
        "    return movie1 < movie2 # Compares movie IDs and returns True if movie ID 2 is greater than movie ID1. This is to reject duplicate movie pairs"
      ],
      "metadata": {
        "id": "3e8uNkyDdH_k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# CosineSimilarity is a measure to calculate distance rather simnilarity between two\n",
        "# sparse vectors, it is widely used by recommendation systems.\n",
        "# The formula for Cosine similarity is Cosinesimilarity = (v1 . V2)/(|V1||V2|)\n",
        "# That is Dot product of vectors divided by mod/magnitude of the vectors.\n",
        "\n",
        "def computeCosineSimilarity(ratingPairs): # Defining a function to accept rating pairs tuple as input\n",
        "    numPairs = 0 #initialising counter value to 0\n",
        "    sum_xx = sum_yy = sum_xy = 0 # initialising the values to 0 for future result storage in the 'for' loop\n",
        "    for ratingX, ratingY in ratingPairs: # 'for' loop to extract ratingX and ratingY from tuple ratingPairs one by one\n",
        "        sum_xx += ratingX * ratingX # multiplies ratingX by itself and accumulates the sum in sum_xx variable\n",
        "        sum_yy += ratingY * ratingY # multiplies ratingY by itself and accumulates the sum in sum_yy variable\n",
        "        sum_xy += ratingX * ratingY # multiplies ratingY by ratingX and accumulates the sum in sum_xy variable\n",
        "        numPairs += 1 # counter for the number of time the loop runs\n",
        "\n",
        "    numerator = sum_xy # sum_xy is assigned to numerator\n",
        "    denominator = sqrt(sum_xx) * sqrt(sum_yy) # square roots of sum_xx and sum_yy is assigned to denominator\n",
        "\n",
        "    score = 0 # score is initialised with the value of 0\n",
        "    if (denominator): # if denominator is not 0 that is if denomonator is True then score is calcuated in the next line\n",
        "        score = (numerator / (float(denominator))) # score calculation, equivalent of Cosine similarity\n",
        "\n",
        "    return (score, numPairs) # the final value of score and the counter value is returned by the function"
      ],
      "metadata": {
        "id": "kKjv5eHqeATO"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "conf = SparkConf().setMaster(\"local[*]\").setAppName(\"MovieSimilarities\") # creates a new Spark object and names the App as MovieSimilarities\n",
        "sc = SparkContext(conf = conf) #entry point for working with spark for connecting with a spark cluster"
      ],
      "metadata": {
        "id": "oEbJLx2DE9BV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# print \"\\nLoading movie names...\"\n",
        "nameDict = loadMovieNames() # calls loadMovieNames function defined earlier to return with key-value pair of movie id and name respectively\n",
        "data = sc.textFile(\"file:///home/cloudera/moviedata/datafile2.txt\") # load movie data from datafile2.txt into the RDD called data"
      ],
      "metadata": {
        "id": "671cjnaPGhku"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ratings = data.map(lambda l: l.split()).map(lambda l: (int(l[0]), (int(l[1]), float(l[2]))))\n",
        "\n",
        "# map(lambda l: l.split()) - splits each line of data into list\n",
        "# map(lambda l: (int(l[0]), (int(l[1]), float(l[2]))) - takes list from first map function and converts\n",
        "# to tuple (userID, (movieID, rating)) where UseerID is and movieID are integers and rating is float\n",
        "\n",
        "joinedRatings = ratings.join(ratings)\n",
        "# ratings RDD self joins into a new RDD giving all pairs of movie rated by the same user in the\n",
        "# following tuple format (userID, ((movieID1, rating1), (movieID2, rating2))......).\n",
        "\n",
        "uniqueJoinedRatings = joinedRatings.filter(filterDuplicates)\n",
        "# run filter function on joinedRatings RDD and retain only the unique movies pairs in uniqueJoinedRatings RDD\n",
        "\n",
        "moviePairs = uniqueJoinedRatings.map(makePairs)\n",
        "# calls previously defined function uniqueJoinedRatings and takes a tuple\n",
        "# in format of (userID, ((movieID1, rating1), (movieID2, rating2))) to returns\n",
        "# tuple in the format of ((movieID1, movieID2), (rating1, rating2))..\n",
        "\n",
        "moviePairRatings = moviePairs.groupByKey()\n",
        "# takes moviepairs and groups them by movie key movieID ((movieID1, movieID2)) in a new RDD\n",
        "\n",
        "moviePairSimilarities = moviePairRatings.mapValues(computeCosineSimilarity).cache()\n",
        "# takes moviePairRatings RDD and calls computeCosineSimilarity function defined earlier to calculate\n",
        "# similarity between each movie pair based on their ratings. The cache() function retains\n",
        "# result in memoory for faster access later."
      ],
      "metadata": {
        "id": "UPNksdG9H6cw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if (len(sys.argv) > 1): # checks if there is a command line argument\n",
        "\n",
        "    scoreThreshold = 0.10 # sets scoreThreshold to 0.1 for similarity\n",
        "    coOccurenceThreshold = 2 # sets value for coOccurenceThreshold to 2, i.e. how often were 2 movie rated together\n",
        "\n",
        "    movieID = int(sys.argv[1]) # extracts movieID from command line argument and typecasts it to integer\n",
        "\n",
        "    filteredResults = moviePairSimilarities.filter(lambda((pair,sim)): \\ # filters earlier calculated RDD on the basis of next 2 lines\n",
        "        (pair[0] == movieID or pair[1] == movieID) \\ # checks if either movie in the pair matches specified movieID\n",
        "        and sim[0] > scoreThreshold and sim[1] > coOccurenceThreshold) # and similarity score and coOccurenceThreshold count is above threshold\n",
        "\n",
        "    results = filteredResults.map(lambda((pair,sim)): (sim, pair)).sortByKey(ascending = False).take(10)\n",
        "    # map(lambda((pair,sim)): (sim, pair)) - swaps order of sim and pair in the tuple\n",
        "    # sortByKey(ascending = False) - sorts the result in descending order of similarity score\n",
        "    # take(10) - Take top 10 results\n",
        "    # output saved in results"
      ],
      "metadata": {
        "id": "i6OTs3gyUjaq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        " print \"Top 10 similar movies for \" + nameDict[movieID]\n",
        " # prints movie using dictionary nameDict[movieID] for which similar movies are being shown\n",
        "    for result in results: # for loop where 'results' has top 10 similar movies from previous block, result variable iterate through the loop\n",
        "        (sim, pair) = result # result tuple into similarity score and pair\n",
        "        similarMovieID = pair[0]\n",
        "        if (similarMovieID == movieID): #checks if assumed similarMovieID is same as orginal movieID\n",
        "            similarMovieID = pair[1] # if condition above is true then updates similarMovieID to second movie in the pair\n",
        "        print nameDict[similarMovieID] + \"\\tscore: \" + str(sim[0]) + \"\\tstrength: \" + str(sim[1])\n",
        "        # prints name of similar movie from nameDict dictionary using key along with similarity score and co-occurence count"
      ],
      "metadata": {
        "id": "PpOKTjtfZaqP"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}